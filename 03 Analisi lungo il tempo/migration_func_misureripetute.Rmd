---
title: "Functional data exploration for country flows"
output:
  html_document:
    df_print: paged
---

## Preparazione dei dati

Carico il dataset.

```{r}
rm(list=ls())
#setwd("~/Documents/Polimi/NONPARAMETRIC/pollini_nonparam/03 Analisi lungo il tempo/")

df <- read.csv("Flows_per_year.csv")
df
```

Processo i dati, prima per l'emigrazione.

```{r}
# obtain going out
df.out <- aggregate(count~startC + year, df[,-2], FUN = sum)
df.out
```

Ora per l'immigrazione

```{r}
# obtain going out
df.in <- aggregate(count~endC + year, df[,-1], FUN = sum)
df.in
```

### Costruzione del dataset con tutte e tre le variabili (in / out / differenza)

```{r}
country <- unique(df$endC)
df.ok <- data.frame(country)

# assign values
for (y in unique(df.out$year)){
  print(y)
  df.ok <- merge(x=df.ok, y=df.out[df.out$year==y,c(1,3)], 
                 by.x = "country",  by.y = "startC")
  names(df.ok)[ncol(df.ok)] = paste(y, "-out") 
  df.ok <- merge(x=df.ok, y=df.in[df.in$year==y,c(1,3)], 
                 by.x = "country",  by.y = "endC")
  names(df.ok)[ncol(df.ok)] = paste(y, "-in") 
  # in - out
  df.ok$new =  df.ok[,ncol(df.ok)] - df.ok[,ncol(df.ok)-1]
  names(df.ok)[ncol(df.ok)] = paste(y, "-total")
}
rownames(df.ok) <- df.ok$country
df.ok
```

Costruzione del dataset

```{r}
# notiamo il seguente fatto:
length(unique(df.in$endC))
length(unique(df.out$startC))
```
Cioè, **ci sono 192 paesi con immigrazione, 35 con dati di emigrazione**.
<br>
Proseguiamo con l'analisi tenendo in conto solo quei trentacinque paesi.

```{r}
df.ok.tot <- df.ok[df.ok$country %in% unique(df.out$startC),sapply(names(df.ok), grepl, pattern="total")]
```

#### Cast a oggetto funzionale

N.B potremmo farlo soltanto per emigrazione, soltanto per immigrazione, o tenendo ambedue in conto (oggetto funzionale multivariabile)

```{r}
library(roahd)
abscissa <- seq(2006,2015)
f_data = fData(abscissa, df.ok.tot)
f_data
plot(f_data, main="Net migration for each country", label=rownames(df.ok.tot))

```

Notiamo che ci vuole uno smoothing per le funzioni. Applichiamo BSpline smoothing essendoché non c'è necessariamente periodicità (in quel caso useremmo una basis di tipo Fourier)

### Smoothing

```{r}
# Load package fda
library(fda)
# Set parameters
m <- 4           # spline order 
degree <- m-1    # spline degree 
# Degree is order - 1
nbasis <- 5
s_basis <- create.bspline.basis(rangeval=c(2006,2015), nbasis=nbasis, norder=m)
# Design matrix

design_basismat <- eval.basis(abscissa, s_basis)
plot(s_basis, main="Bases")
# Least squares fit
df.tot.fd <- smooth.basis(argvals=abscissa, y=t(df.ok.tot), fdParobj=s_basis)
abscissa_prec <- seq(2006, 2015, .5)
df.tot.smooth <- eval.fd(abscissa_prec, df.tot.fd$fd) #  the curve smoothing the data

#lsfit(design_basismat, t(df.ok.tot), intercept=FALSE)$coef
# smoothed data
#df.tot.smooth <- basismat %*% lsfit(basismat, t(df.ok.tot), intercept=FALSE)$coef

plot(f_data, main="Original data")
plot(df.tot.fd, main="Smoothed data")


```

N.B the selection of the number of bases and of order should be carried out with GCV.

# Analisi funzionale esploratorio

### Multivariate Band Depth - Median

```{r}
smooth_f_data = fData(abscissa_prec, t(df.tot.smooth))
modified_band_depth <- MBD(Data = smooth_f_data) # mean lebesgue measure of a function included in a pair; proportion of time inside the bands, used to avoid pairs
median_f <- smooth_f_data[which.max(modified_band_depth),]
plot(smooth_f_data)
grid <- seq(median_f$t0, median_f$tP, by=median_f$h)
lines(abscissa_prec,median_f$values)
# print modified band depth
modified_band_depth
```

### Functional boxplot - modified band depth (MBD)

Since usin gthe modified band depth, the depths are obtained by average section each function is contained by other functions. 

```{r}
mag_outlier <- roahd::fbplot(smooth_f_data, Depths = "MBD", main="Magnitude outliers", display=T)
```

```{r}
mag_outlier$ID_outliers
```

### Outliergram

```{r}

outliers = outliergram(smooth_f_data)

```

Vediamo quali sono gli outlier:

```{r}
outliers$ID_outliers
```

### Dati normalizzati
```{r}
#setwd("~/Documents/Polimi/NONPARAMETRIC/pollini_nonparam/00 Tabelle importanti/")
aux.df <- read.csv(file="Eco_data_29_10_21.csv")
aux.df = aux.df[, c(1, ncol(aux.df))]
aux.df
```
```{r}
#setwd("~/Documents/Polimi/NONPARAMETRIC/pollini_nonparam/03 Analisi lungo il tempo/")
df.ok.tot <- merge(df.ok.tot, aux.df, by.x="row.names", by.y="Country")
row.names(df.ok.tot) <- df.ok.tot[,1]
df.ok.tot = df.ok.tot[,-1]
# perform normalization
df.ok.tot[,-ncol(df.ok.tot)] <- sweep(df.ok.tot[,-ncol(df.ok.tot)], 1,df.ok.tot[, ncol(df.ok.tot)], "/")
# drop column
df.ok.tot <- df.ok.tot[, -ncol(df.ok.tot)]
f_data = fData(abscissa, df.ok.tot)
f_data
```
Perform smoothing:
```{r}
plot(f_data, main="Net normalized migration for each country", label=rownames(df.ok.tot))
# Set parameters
m <- 4           # spline order 
degree <- m-1    # spline degree 
# Degree is order - 1
nbasis <- 10
s_basis <- create.bspline.basis(rangeval=c(2006,2015), nbasis=nbasis, norder=m)
# penalise oscillations on first derivative
fit_obj <- fdPar(fdobj=s_basis, Lfdobj=2,lambda=1e-1)
# Design matrix

design_basismat <- eval.basis(abscissa, s_basis)
# Least squares fit
df.tot.fd <- smooth.basis(argvals=abscissa, y=t(df.ok.tot), fdParobj=fit_obj)
abscissa_prec <- seq(2006, 2015, .5)
df.tot.smooth <- eval.fd(abscissa_prec, df.tot.fd$fd) #  the curve smoothing the data
plot(df.tot.fd, main="Smoothed normalized data")
plot(df.tot.fd, Lfdobj=1, main="First derivative")
```

Visualize without the magnitude outliers:
```{r}
smooth_f_data = fData(abscissa_prec, t(df.tot.smooth))
d0.outliers <- roahd::fbplot(smooth_f_data, Depths = "MBD" , main="Magnitude outliers", display=T)$ID_outliers
plot(smooth_f_data[-5], main="Plot without CY")
d0.outliers

```
The result is quite interesting. 1/5 of the population is an outlier when taking into account the normalization by researchers.
We also look at their outliergram
```{r}
out.norm <- outliergram(smooth_f_data)
out.norm$ID_outliers
```


What if we look at the derivative, i.e. how many net researchers coming into the country (can be negative when there is more emigration than immigration)
```{r}
df.tot.smooth.d1 <- eval.fd(abscissa_prec, df.tot.fd$fd, Lfdobj = 1)
smooth_f_data_d1 = fData(abscissa_prec, t(df.tot.smooth.d1))
d1.outliers <- roahd::fbplot(smooth_f_data_d1, Depths = "MBD" , main="Magnitude outliers- first derivative", display=T)$ID_outliers
d1.outliers
d0.outliers %in% d1.outliers
```
More outliers may be a consequence of using the first derivative (and hence taking into account noise, rather than something meaningful), since all the original outliers are contained in these new ones. There is only one exception.
```{r}
out.d1 <- outliergram(smooth_f_data_d1)
```
Provvediamo ad eseguire il kma, per i dati senza Cipro.
```{r}
library(fdakma)
fdakma_example_noalign_0der <- invisible(kma(
  x=abscissa_prec, y0=t(df.tot.smooth), n.clust = 2, 
  warping.method = "shift",  # without aligning
  similarity.method = 'd0.L2',   # similarity computed as the cosine
                                      # between the original curves 
                                      # (correlation)
  center.method = 'k-means' # or k-medoids
  ,seeds = c(3,4)# you can give a little help to the algorithm...
  ,optim.method = "L-BFGS-B"
))

```
```{r}
fdakma_example_noalign_0der$labels
```

```{r}
#library(fdakma)
#kma.compare_example3 <- kma.compare (
#  x=abscissa_prec, y0=t(as.matrix(df.tot.smooth)), y1=t(as.matrix(df.tot.smooth.d1)), n.clust = 1:3, 
#  warping.method = c('NOalignment', 'shift', 'dilation', 'affine'), 
 # similarity.method = 'd1.pearson',
  #center.method = 'k-means', 
  #seeds = c(1,13,12),
  #plot.graph=1)
```




# Alternative - prossimi passi
### Analisi funzionale
##### 1. Test uguaglianza di covarianza
##### 2. Mahalanobis  

### Analisi misure ripetute (test multivariati)
#### Test classico misure ripetute


#### Test di profili paralleli
Verificare se i profili sono paralleli, ossia se i contrasti corrispondono: $H_0: \mu_{1t} - \mu_{1t-1} = \mu_{2t} - \mu_{2t-1}, t=t_2,t_3,...,t_N$ 
Ovvero:
$ H_0: \mathbf{C\mu_1} = \mathbf{C\mu_2} $ vs $\ H_1: \mathbf{C\mu_1} \ne \mathbf{C\mu_2}\ $
Lo statistico dunque è:
$T_0 := (\mathbf{\bar{x}}_1 - \mathbf{\bar{x}}_2)' \mathbf{C}'[(\frac{1}{n_1} + \frac{1}{n_2})\mathbf{CSC'}]^{-1} \mathbf{C} (\mathbf{\bar{x}}_1 - \mathbf{\bar{x}}_2)$.

#### Test di profili coincidenti
 Supponendo che siano paralleli, sono coincidenti?
 $H_0: \mathbf{1'\mu_1} = \mathbf{1'\mu_2}$
 
#### Test di profili livellati
 Caso visto a lezione. Le variazioni nella media sono 0 lungo il tempo (o trattamenti)
 $H_0: \mathbf{C\mu} = \mathbf{0}$
 
# TODO:
1. Perform smoothing with penalised splines.
 